# 数据库导入
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from sklearn.datasets import fetch_olivetti_faces
import numpy as np
from torchvision import transforms

# 自定义数据集类
class OlivettiFacesDataset(Dataset):
    def __init__(self, data, labels, transform=None):
        self.data = data
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        image = self.data[idx]
        label = self.labels[idx]
        image = np.expand_dims(image, axis=0)  # 添加通道维度，形状变为 [1, height, width]
        if self.transform:
            image = self.transform(image)
        return image, label

# 定义模型
class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.fc1 = nn.Linear(20 * 13 * 13, 50)  # 输入尺寸调整
        self.fc2 = nn.Linear(50, 40)  # 40个类别

    def forward(self, x):
        x = torch.relu(torch.max_pool2d(self.conv1(x), 2))
        x = torch.relu(torch.max_pool2d(self.conv2(x), 2))
        x = x.view(-1, 20 * 13 * 13)  # 展平
        x = torch.relu(self.fc1(x))
        return self.fc2(x)

# 加载 Olivetti Faces 数据集
data = fetch_olivetti_faces()
images = data.images  # 形状为 [400, 64, 64]
labels = data.target

# 数据预处理
transform = transforms.Compose([
    transforms.ToTensor(),  # 转换为张量并自动调整为 [1, 64, 64]
    transforms.Normalize((0.5,), (0.5,))
])

# 划分训练集和测试集
from sklearn.model_selection import train_test_split
train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)

train_dataset = OlivettiFacesDataset(train_images, train_labels, transform=transform)
test_dataset = OlivettiFacesDataset(test_images, test_labels, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# 初始化模型、损失函数和优化器
model = SimpleModel()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 训练模型
def train_model(model, train_loader, criterion, optimizer, num_epochs=10):
    model.train()
    for epoch in range(num_epochs):
        running_loss = 0.0
        for batch_idx, (data, target) in enumerate(train_loader):
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            if batch_idx % 10 == 9:  # 每10批次打印一次
                print(f'Epoch {epoch + 1}, Batch {batch_idx + 1}, Loss: {running_loss / 10:.3f}')
                running_loss = 0.0

train_model(model, train_loader, criterion, optimizer, num_epochs=10)

# 测试模型
def test_model(model, test_loader):
    model.eval()
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            output = model(data)
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
    print(f'Test set: Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.2f}%)')

test_model(model, test_loader)
